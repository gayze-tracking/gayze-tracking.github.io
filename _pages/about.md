---
permalink: /
title: "Computing for Social Good Group"
author_profile: false
redirect_from: 
  - /about/
  - /about.html
---



About Us
------

Our interdisciplinary research group crosses boundaries of machine learning and artificial intelligence, the public and private sector, individuals and society to search for how to create a better world for everyone, one program at a time.

We believe that the use of ML and AI is critical in improving the lives of everyone in an unbiased, fair, and ethical manner.

Our work includes using the power of Deep Learning to explain the unexplainable; creating high-impact unbiased artificially intelligent tools with government, academic, and corporate partners; and adopting bleeding-edge technologies for social good.



Publications
------

Fake Author Name. (2020). *Development of a Machine Learning Model to Track Gays on Social Media*. JAMA Network Open.  ([Open Access Link](https://jamanetwork.com/journals/jamanetworkopen/))


Press
------

[Kotaku](https://kotaku.com/activision-blizzard-diversity-tool-overwatch-2-call-of-1848924832) (2022) - Activision Blizzard’s New Diversity Game Tool Is Met With Fanfare: DEI Experts Say This Could Be the Next Killer App in Game Dev

<img src="https://user-images.githubusercontent.com/28931962/179066100-e081b858-a1e8-44e7-a46c-4e1b2f004e45.png" width="100%">

<br><br>


[The Verge](https://www.theverge.com/2021/4/8/22373290/intel-bleep-ai-powered-abuse-toxicity-gaming-filters) (2021) - Empowering Gamers To Customize Prefered Amount Toxicity of Filter Toxic Through AI Sliders

<img src="https://user-images.githubusercontent.com/28931962/179065811-89a7ea3e-a737-4ac2-87b1-e9fd7df3cd24.png" width="100%" style="margin-bottom:5%">

<img src="https://user-images.githubusercontent.com/28931962/179066039-ff816764-6345-4ad9-a201-a92f55397e6b.png" width="100%">

<br><br>


[The Verge](https://www.theverge.com/2017/9/21/16332760/ai-sexuality-gaydar-photo-physiognomy) (2017) - The Invention of AI ‘Gaydar’ Could Be the Start of Something Great: What Else Can We Predict From People’s Faces?

<img src="https://user-images.githubusercontent.com/28931962/179066394-356963f8-1bc3-4565-b00f-a44fc48e5c4d.png" width="100%">



Grants
------

National Science Foundation (2021) - "Fairness in Artificial Intelligence in Collaboration with Amazon" ($1.5M)



Courses
------

| Semester | Course Name |
| :------ | :--- | 
| Soring 20222 | CS 3000: Participatory Design & FATE |
| Spring 2021 | CS 3000: Fair, Accountable, Transparent, and Equitable AI |
| Spring 2020 | CS 3000: Fair, Accountable and Transparent AI for Social Good |
| Spring 2019 | CS 3000: Ethical Natural Language Processing for Social Good |
| Fall 2018 | CS 4002: Deep Natural Language Processing & Deeper Learning |
| Spring 2018 | CS 3000: Ethical AI |
| Fall 2017 | CS 4001: Natural Language Processing & Deep Learning |
| Fall 2016 | CS 4000: Natural Language Processing |
| Fall 2015 | CS 4000: Natural Language Processing |
| Fall 2014 | CS 4000: Natural Language Processing |
| Fall 2013 | CS 4000: Natural Language Processing |
